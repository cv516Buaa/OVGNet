
<p align="center">
  <h1 align="center">OVGNet: An Unified Visual-Linguistic Framework for Open-Vocabulary Robotic Grasping</h1>
  <p align="center">


   <br />
    <strong>Meng Li</strong></a>
    ·
    <strong>Qi Zhao</strong></a>
    ·
    <a href="https://cv-shuchanglyu.github.io/EnHome.html"><strong>Shuchang Lyu</strong></a>
    ·
    <strong>Chunlei Wang</strong></a>    
    ·
    <strong>Yujing Ma</strong></a>
    ·
    <a href="https://cv-shuchanglyu.github.io/EnHome.html"><strong>Shuchang Lyu</strong></a>
    ·
    <a href="https://sites.google.com/view/guangliangcheng"><strong>Guangliang Cheng</strong></a>
    <br />
<p align="center">

    
  </p>





## Highlight!!!!
This repo is the implementation of "OVGNet: An Unified Visual-Linguistic Framework for Open-Vocabulary Robotic Grasping". we refer to [Vision-Language-Grasping](https://github.com/xukechun/Vision-Language-Grasping). Many thanks to this excellent repos.

## TODO
- [x] Release grapsping demo
- [ ] Release framework
- [ ] Release DATASET

## Demo Setting
**Novel** indicates the **unseen** objects in training.
<br />
**Base** denotes the **seen** objects in training.
<br />
Battery and power drill are novel classes with irregular shapes, which belong to hard task.
<br />
Apple and pear are base classes, which belong to simple task.
<br />

      

## Grasping Demo
[Demo](https://github.com/cv516Buaa/OVGNet/assets/94512783/1ff2e4d6-83a5-450d-ba7a-ad2616bdb31c)


## Install

## Cite

```
